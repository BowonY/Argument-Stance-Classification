{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Predict the topic labels of discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "We apply the natural language technologies, such as n-gram and stemming, we've learned in class to generate useful features and evaluate their effectiveness on classifying argument discussions into 10 labeled topic groups. The architecture for this task is as below:\n",
    "\n",
    "![alt text](imgs/task1-arch.png \"Architecture\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "| Topic        | # of discussions  |\n",
    "| ------------- |:-------------:|\n",
    "| abortion | 564 |\n",
    "| climate change | 40 |\n",
    "| communism vs capitalism | 38 |\n",
    "| death penalty | 25 |\n",
    "| evolution | 871 |\n",
    "| existence of God | 105 |\n",
    "| gay marriage | 305 |\n",
    "| gun control | 824 |\n",
    "| healthcare | 81 |\n",
    "| marijuana legalization | 13 |\n",
    "\n",
    "\n",
    "\n",
    "For each discussion, \n",
    "1. We first filtered characters that are neither numbers nor english letters (e.g. \"[A-Za-z0-9]\" in regular expression). \n",
    "2. We filtered stopwords in text. The stopword list, which contains 2,400 stopwords for 11 languages, is from the stopword corpus created by Porter et al. (2001). \n",
    "3. We adopted Porter stemmer to convert words in dicussions to their stemmed form. There are 98,988 distinct stems used in our dataset.\n",
    "4. We took the stems as unigrams and built an unigram occurrence vector as the representation of discussion.\n",
    "\n",
    "Since the number of unigrams is large, most of representation vectors are sparse. It is an known issue which may affect classification performance. Our future goal would be adopt some dimension reduction methods to reduce the size of feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Classification\n",
    "We split the dataset into 75% stratified training data and 25% testing data. We trained a multi-class SVM model with linear kernel (LIBSVM, proposed by Chang et al., 2011). We performed 5-fold cross validation and the average accuracy is 87.58%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset files...\n",
      "5000 dicussions were loaded\n",
      "10000 dicussions were loaded\n",
      "11799 dicussions were loaded\n",
      "Loading topic file...\n",
      "Loading author stance file...\n",
      "===== Start preprocessing =====\n",
      "[nltk_data] Downloading package stopwords to /home/tomelf/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Load unigram_dict ... \n",
      "Load discussions_unigram_label_dict ... \n",
      "1000 discussions were loaded\n",
      "2000 discussions were loaded\n",
      "2865 discussions were loaded\n",
      "===== Done! =====\n",
      "Divide data into train/test sets\n",
      "Load pre-trained SVM model\n",
      "5-fold cross validation: [ 0.88541667  0.88327526  0.85888502  0.86713287  0.88421053]\n"
     ]
    }
   ],
   "source": [
    "# Run task1.py\n",
    "# - The testing accuracy is about 87%. \n",
    "# - The SVM model (kernel='linear', Penalty parameter C=1) is saved as svm_model.pkl\n",
    "# - Some additional dump files:\n",
    "#     - unigram_dict.pickle: binary dump of unigram_dict\n",
    "#     - unigram_dict.txt: list all unigrams\n",
    "#     - discussions_unigram_label_dict.txt: unigram vectors of dicussions, the format of each row: \n",
    "#     \"[Discussion ID],[Discussion Topic Label in text],[Discussion Unigram Occurance Vector]\"\n",
    "# - The trained model can achieve higher than 90% accuracy when testing on all discussions\n",
    "# - The accuracy when doing 5-fold cross validation: [ 0.88541667  0.88327526  0.85888502  0.86713287  0.88421053]\n",
    "\n",
    "import task1\n",
    "task1.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
